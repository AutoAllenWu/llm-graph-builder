{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../backend'))\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from graphdatascience import GraphDataScience\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from src.llm import get_llm\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "from neo4j import GraphDatabase, Result\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# from llama_index.core.schema import TextNode\n",
    "# from llama_index.core.vector_stores.utils import node_to_metadata_dict\n",
    "# from llama_index.vector_stores.neo4jvector import Neo4jVectorStore\n",
    "# from llama_index.core import VectorStoreIndex\n",
    "from tqdm import tqdm\n",
    "from src.shared.common_fn import load_embedding_model\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from typing import Dict, Any\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from src.llm import get_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NEO4J_URI\"] = \"\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"\"\n",
    "\n",
    "url = os.environ[\"NEO4J_URI\"]\n",
    "username =  os.environ[\"NEO4J_USERNAME\"]\n",
    "password = os.environ[\"NEO4J_PASSWORD\"] \n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n",
    "\n",
    "llm = AzureChatOpenAI(temperature=0,azure_deployment=\"gpt-35\",\n",
    "    api_version=\"2024-02-15-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds = GraphDataScience(\n",
    "    os.environ[\"NEO4J_URI\"],\n",
    "    auth=(os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
    ")\n",
    "\n",
    "graph = Neo4jGraph() \n",
    "\n",
    "driver = GraphDatabase.driver(os.environ[\"NEO4J_URI\"], auth=(os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## local search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, dimension = load_embedding_model(\"sentence_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_retrieval_query = \"\"\"\n",
    "WITH collect(node) AS nodes\n",
    "UNWIND nodes AS n\n",
    "MATCH (n)<-[:HAS_ENTITY]-(c:Chunk)\n",
    "WITH c, count(distinct n) AS freq, nodes\n",
    "ORDER BY freq DESC\n",
    "WITH collect({chunkText: c.text}) AS text_ref, nodes\n",
    "UNWIND nodes AS n\n",
    "MATCH (n)-[:IN_COMMUNITY]->(c:`__Community__`)\n",
    "WITH text_ref,collect({community:c.summary}) as community,nodes\n",
    "UNWIND nodes AS n\n",
    "MATCH (n)-[r]-(m)\n",
    "WITH text_ref, community, collect([n.id, TYPE(r), m.id, CASE \n",
    "    WHEN (n)-[r]->(m) THEN \"outgoing\"\n",
    "    WHEN (n)<-[r]-(m) THEN \"incoming\"\n",
    "    ELSE \"undirected\"\n",
    "END]) AS Triples\n",
    "RETURN {Chunks: text_ref, Community: community } AS text, 1.0 AS score, {Triples: Triples} AS metadata\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_graph= Neo4jVector.from_existing_graph(\n",
    "            embedding = embeddings,\n",
    "            url=url,\n",
    "            username=username,\n",
    "            password=password,\n",
    "            index_name=\"entity\",\n",
    "            node_label=\"__Entity__\",\n",
    "            text_node_properties=[\"id\"],\n",
    "            embedding_node_property=\"embedding\",\n",
    "            retrieval_query=lc_retrieval_query \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given information, the answer to the question \"Who killed Dumbledore?\" is not in the context.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an assistant tasked with extracting answers from the retrieve from the local_retrieval. The answer contains triplates as well as infomation of the nodes in chunks_details and community_summary.\n",
    "Triplates : {triples} from Triplates Understand the 'outgoing' are outgoing relations and 'incoming' are incoming relations\n",
    "and refer this : {chunks} for further reference based on above information.\n",
    " provide a concise and accurate answer to the question:\n",
    "\"{question}\"\n",
    "Provide the correct information in detailed explaination. If the context does not contain sufficient information to answer the question, respond with \"The answer is not in the context.\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"triples\", \"chunks\", \"question\"], template=prompt_template)\n",
    "\n",
    "\n",
    "def create_contextual_extraction_chain():\n",
    "    return LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "question = \"Who killed Dumbledore?\"\n",
    "docs = existing_graph.similarity_search(question,k=1)\n",
    "chain = create_contextual_extraction_chain()\n",
    "\n",
    "for doc in docs:\n",
    "    metadata = doc.metadata\n",
    "    page_content = doc.page_content\n",
    "    \n",
    "answer = chain.run(triples=metadata,chunks=page_content, question=question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Triples': [['Dumbledore', 'HAS_ENTITY', '18c2734716cad5d4df0bc03052857103249f330c', 'incoming'], ['Dumbledore', 'HAS_ENTITY', 'eb31684a257572d0260ab0d5dd15c148e377e5dc', 'incoming'], ['Dumbledore', 'HAS_ENTITY', 'b5c5a7c16c8449ac670e6e581d1077d73403b0e5', 'incoming'], ['Dumbledore', 'HAS_ENTITY', '3a6ea1c351161c3dd308263eded1a60f9e8d15d3', 'incoming'], ['Dumbledore', 'HAS_ENTITY', '98fcf19af9f513628792c4d1888c1f1d85f9add8', 'incoming'], ['Dumbledore', 'HAS_SUPPORTER', 'Voldemort', 'incoming'], ['Dumbledore', 'HAS_SUPPORTER', 'Harry', 'incoming'], ['Dumbledore', 'IN_COMMUNITY', '0-24', 'outgoing']]}, page_content=\"Community:\\n- {'community': 'Voldemort is supported by Nagini, Snape, and Dumbledore, forming a network of allies.'}\\nChunks:\\n- {'chunkText': ' was in her vault at  Gringotts bank. She is very concerned about anything else they might have taken.  Dobby, the Malfoys’ former house-elf, helps Harry and his friends to escape, along  with Ollivander the wand maker, Luna Lovegood, and Griphook the goblin. Harry  takes them all to Ron’s brother Bill’s cottage.  Harry guesses that Voldemort has a Horcrux stored in Bellatrix’s vault, since she  seemed so worried about it, and he persuades Griphook the goblin to help him  break into the vault. With Griphook’s help, Harry, Ron, and Hermione break in and  steal the Hufflepuff Cup from the vault, then escape on the back of a dragon.  Harry learns from a vision of Voldemort’s that the final Horcrux is at Hogwarts, so  they travel to the nearby village of'}\\n- {'chunkText': 's that the final Horcrux is at Hogwarts, so  they travel to the nearby village of Hogsmeade. There they meet Aberforth,  Dumbledore’s brother, who helps them get into Hogwarts through a painting by  summoning Neville Longbottom, who has been organizing meetings of  Dumbledore’s Army in the hidden Room of Requirement. Harry asks the members of  the D.A., who are all his supporters, if they can think of an important item associated  with the school, hoping such an item might be the final Horcrux. The Ravenclaw  students tell him about the lost diadem of Ravenclaw.  '}\\n- {'chunkText': 'While Harry looks for the diadem, the professors and students of Hogwarts rally to  his defense, having been warned that Voldemort is on his way. Voldemort and his  followers attack the school in a great battle, and Harry finds and destroys the  diadem Horcrux.  Harry witnesses Voldemort murdering Snape in order to take possession of  Dumbledore’s powerful wand (since Snape killed Dumbledore, Snape is presumably  the wand’s true master until someone kills him). Before he dies, Snape gives Harry  his memories, extracted for viewing in the Pensieve.  Harry goes to the Pensieve in the headmaster’s office and views the most important  moments of Snape’s life. He learns that he has been completely mistaken about  Snape, who loved Harry’s mother, Lily Potter, his whole life. Snape had spent his  entire adult life spying on Voldemort for Dumbledore and working to protect Harry.  From one of Snape’s conversations'}\\n- {'chunkText': ' spying on Voldemort for Dumbledore and working to protect Harry.  From one of Snape’s conversations with Dumbledore, Harry learns that there’s a  piece of Voldemort’s soul inside him (Harry is in fact the final Horcrux), and that he  will have to let Voldemort kill him before Voldemort can die. He goes into the forest  and lets Voldemort kill him, then wakes up in a dreamlike version of King’s Cross  train station, where Dumbledore meets him and tells him that he hasn’t died, and  that the protective charm Lily Potter placed on Harry is kept alive inside of  Voldemort, because Voldemort used Harry’s blood to reconstitute himself. Thus,  Voldemort could not kill Harry, and Harry can now go back and finish him off.  Voldemort takes Harry, whom he believes to be dead, back to Hogwarts to demand  its surrender. The students and teachers defy Voldemort, and Neville uses the  Sword'}\\n- {'chunkText': ' Hogwarts to demand  its surrender. The students and teachers defy Voldemort, and Neville uses the  Sword of Gryffindor to kill the giant snake, Nagini, which was the last Horcrux  keeping Voldemort invulnerable. A final battle erupts, and Harry reveals that he’s  still alive, going on to kill Voldemort in a duel.  In an Epilogue set nineteen years later, Harry is married to Ginny and is sending their  children to Hogwarts. Ron and Hermione are married, and their families are both  thriving.    '}\\n\")]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDUCE_SYSTEM_PROMPT = \"\"\"\n",
    "---Role---\n",
    "You are a helpful assistant responding to questions about a dataset by synthesizing perspectives from multiple analysts.\n",
    "---Goal---\n",
    "Generate a response of the target length and format that responds to the user's question, summarize all the reports from multiple analysts who focused on different parts of the dataset.\n",
    "If you don't know the answer or if the provided reports do not contain sufficient information to provide an answer, just say so. Do not make anything up.\n",
    "The final response should remove all irrelevant information from the analysts' reports and merge the cleaned information into a comprehensive answer that provides explanations of all the key points and implications appropriate for the response length and format.\n",
    "Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\n",
    "The response shall preserve the original meaning and use of modal verbs such as \"shall\", \"may\" or \"will\".\n",
    "\n",
    "**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
    "\n",
    "Do not include information where the supporting evidence for it is not provided.\n",
    "\n",
    "---Target response length and format---\n",
    "{response_type}\n",
    "\n",
    "---Analyst Reports---\n",
    "\n",
    "{report_data}\n",
    "\n",
    "Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            REDUCE_SYSTEM_PROMPT,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "reduce_chain = reduce_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_SYSTEM_PROMPT = \"\"\"\n",
    "---Role---\n",
    "\n",
    "You are a helpful assistant responding to questions about data in the tables provided.\n",
    "\n",
    "\n",
    "---Goal---\n",
    "\n",
    "Generate a response consisting of a list of key points that responds to the user's question, summarizing all relevant information in the input data tables.\n",
    "\n",
    "You should use the data provided in the data tables below as the primary context for generating the response.\n",
    "If you don't know the answer or if the input data tables do not contain sufficient information to provide an answer, just say so. Do not make anything up.\n",
    "\n",
    "Each key point in the response should have the following element:\n",
    "- Description: A comprehensive description of the point.\n",
    "- Importance Score: An integer score between 0-100 that indicates how important the point is in answering the user's question. An 'I don't know' type of response should have a score of 0.\n",
    "\n",
    "The response should be JSON formatted as follows:\n",
    "{{\n",
    "    \"points\": [\n",
    "        {{\"description\": \"Description of point 1 [Data: Reports (report ids)]\", \"score\": score_value}},\n",
    "        {{\"description\": \"Description of point 2 [Data: Reports (report ids)]\", \"score\": score_value}}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "The response shall preserve the original meaning and use of modal verbs such as \"shall\", \"may\" or \"will\".\n",
    "\n",
    "Points supported by data should list the relevant reports as references as follows:\n",
    "\"This is an example sentence supported by data references [Data: Reports (report ids)]\"\n",
    "\n",
    "**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
    "\n",
    "For example:\n",
    "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (2, 7, 64, 46, 34, +more)]. He is also CEO of company X [Data: Reports (1, 3)]\"\n",
    "\n",
    "where 1, 2, 3, 7, 34, 46, and 64 represent the id (not the index) of the relevant data report in the provided tables.\n",
    "\n",
    "Do not include information where the supporting evidence for it is not provided.\n",
    "\n",
    "\n",
    "---Data tables---\n",
    "\n",
    "{context_data}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            MAP_SYSTEM_PROMPT,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "map_chain = map_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_type: str = \"multiple paragraphs\"\n",
    "\n",
    "\n",
    "def global_retriever(query: str,  response_type: str = response_type) -> str:\n",
    "    community_data = graph.query(\n",
    "        \"\"\"\n",
    "        CALL db.index.fulltext.queryNodes(\"community_keyword\", $query) YIELD node, score RETURN node.summary as output LIMIT 10\n",
    "    \"\"\",\n",
    "        params={\"query\":query},\n",
    "    )\n",
    "    \n",
    "    intermediate_results = []\n",
    "    for community in range(len(community_data)):\n",
    "        intermediate_response = map_chain.invoke(\n",
    "            {\"question\": query, \"context_data\": community_data[community][\"output\"]}\n",
    "        )\n",
    "        intermediate_results.append(intermediate_response)\n",
    "    final_response = reduce_chain.invoke(\n",
    "        {\n",
    "            \"report_data\": intermediate_results,\n",
    "            \"question\": query,\n",
    "            \"response_type\": response_type,\n",
    "        }\n",
    "    )\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_type: str = \"multiple paragraphs\"\n",
    "\n",
    "\n",
    "def global_retriever(query: str, level: int, response_type: str = response_type) -> str:\n",
    "    community_data = graph.query(\n",
    "        \"\"\"\n",
    "    MATCH (c:__Community__)\n",
    "    WHERE c.level = $level\n",
    "    RETURN c.summary AS output LIMIT 25\n",
    "    \"\"\",\n",
    "        params={\"level\": level},\n",
    "    )\n",
    "    \n",
    "    intermediate_results = []\n",
    "    for community in range(len(community_data)):\n",
    "        intermediate_response = map_chain.invoke(\n",
    "            {\"question\": query, \"context_data\": community_data[community][\"output\"]}\n",
    "        )\n",
    "        intermediate_results.append(intermediate_response)\n",
    "    final_response = reduce_chain.invoke(\n",
    "        {\n",
    "            \"report_data\": intermediate_results,\n",
    "            \"question\": query,\n",
    "            \"response_type\": response_type,\n",
    "        }\n",
    "    )\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have any information about who killed Snape in the provided data tables. I have reviewed multiple analyst reports, and none of them contain any information regarding Snape's killer. It seems that the dataset does not include this specific information.\n",
      "\n",
      "It is important to note that the absence of information about Snape's killer in the dataset does not necessarily mean that it is impossible to determine. It may be that the dataset does not include the necessary details or that the analysts did not focus on this particular aspect.\n",
      "\n",
      "If you have any other questions or if there is any other information you would like me to look for in the dataset, please let me know and I will do my best to assist you.\n"
     ]
    }
   ],
   "source": [
    "print(global_retriever(\"Who killed Dumbledore?\",1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drift Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    \"\"\"Information about answer\"\"\"\n",
    "    answer: Optional[str] = Field(default=None, description=\"The answer returned from any search methods \")\n",
    "    additional_info: Optional[str] = Field(\n",
    "        default=None, description=\"Any imporant additional infomation retrieved during global search\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert in extracting answer. there are two answers passed to a {question} compare both and extract proper answer for the question , with detailed explanation  present in any of them \"\n",
    "            \"Only extract relevant information from the text with some addition proof for the answer, answer should be details. specific  \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        (\"human\", \"Global Search Answer : {global_answer}, Local Search Answer : {local_answer}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(schema=Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:neo4j.io:Failed to read from defunct connection IPv4Address(('54.89.254.144', 7687)) (ResolvedIPv4Address(('54.89.254.144', 7687)))\n",
      "WARNING:neo4j.pool:Transaction failed and will be retried in 0.8891444630873133s (Failed to read from defunct connection IPv4Address(('54.89.254.144', 7687)) (ResolvedIPv4Address(('54.89.254.144', 7687))))\n",
      "ERROR:neo4j.io:Failed to read from defunct connection IPv4Address(('54.89.254.144', 7687)) (ResolvedIPv4Address(('54.89.254.144', 7687)))\n",
      "WARNING:neo4j.pool:Transaction failed and will be retried in 1.1560854985177507s (Failed to read from defunct connection IPv4Address(('54.89.254.144', 7687)) (ResolvedIPv4Address(('54.89.254.144', 7687))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Answer(answer=\"The available data does not provide any insights into the identity of Dumbledore's killer.\", additional_info=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Who killed Dumbledore?\"\n",
    "global_answer = global_retriever(question,1)\n",
    "docs = existing_graph.similarity_search(question,k=1)\n",
    "chain = create_contextual_extraction_chain()\n",
    "\n",
    "for doc in docs:\n",
    "    metadata = doc.metadata\n",
    "    page_content = doc.page_content\n",
    "    \n",
    "local_answer = chain.run(triples=metadata,chunks=page_content, question=question)\n",
    "\n",
    "\n",
    "prompt = prompt_template.invoke({\"global_answer\": global_answer,\"local_answer\":local_answer,\"question\":question})\n",
    "structured_llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Answer(answer=\"I'm sorry, but I don't have any information about who killed Snape in the provided data tables.\", additional_info=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"who killed Sanpe?\"\n",
    "global_answer = global_retriever(question)\n",
    "docs = existing_graph.similarity_search(question,k=1)\n",
    "\n",
    "for doc in docs:\n",
    "    metadata = doc.metadata\n",
    "    page_content = doc.page_content\n",
    "    \n",
    "local_answer = chain.run(triples=metadata,chunks=page_content, question=question)\n",
    "\n",
    "\n",
    "prompt = prompt_template.invoke({\"global_answer\": global_answer,\"local_answer\":local_answer,\"question\":question})\n",
    "structured_llm.invoke(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
